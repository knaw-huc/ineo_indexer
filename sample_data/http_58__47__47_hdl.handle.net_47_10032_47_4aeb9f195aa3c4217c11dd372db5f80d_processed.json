[
  {
    "operation": "create",
    "document": {
      "id": "http_58__47__47_hdl.handle.net_47_10032_47_4aeb9f195aa3c4217c11dd372db5f80d",
      "title": "RobBERT: A Dutch RoBERTa-based Language Model",
      "intro": "Pre-trained language models have been dominating the field of natural language processing in recent years, and have led to significant performance gains for various complex natural language tasks. One of the most prominent pre-trained language models is BERT. Although the multilingual v...",
      "publishedAt": [],
      "media": {
        "thumbnail": [],
        "slider": []
      },
      "tabs": {
        "overview": {},
        "learn": {},
        "mentions": {},
        "metadata": {}
      },
      "properties": {
        "programmingLanguages": [],
        "learn": [],
        "resourceHost": null,
        "funding": [],
        "problemContact": [],
        "informationTypes": null,
        "languages": [
          "Dutch"
        ],
        "access": [
          {
            "title": "UNSPECIFIED",
            "link": "http://opensource.org/licenses/MIT"
          }
        ],
        "sourceCodeLocation": [],
        "researchContact": [],
        "generalContact": [],
        "resourceTypes": [
          "Data"
        ],
        "status": null,
        "versions": [],
        "standards": [],
        "resourceOwner": null,
        "link": "http://hdl.handle.net/10032/6b69fbaea34aa27c04851a27283be750",
        "intro": "Pre-trained language models have been dominating the field of natural language processing in recent years, and have led to significant performance gains for various complex natural language tasks. One of the most prominent pre-trained language models is BERT. Although the multilingual v...",
        "researchActivities": [],
        "researchDomains": null,
        "mediaTypes": null,
        "provenance": [],
        "community": [],
        "development": null
      }
    }
  }
]